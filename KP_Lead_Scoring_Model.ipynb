{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- COMET setup (new cell at very top of notebook) ---\n",
    "%pip install -q comet_ml\n",
    "\n",
    "import comet_ml\n",
    "\n",
    "exp = None\n",
    "try:\n",
    "    comet_ml.login()\n",
    "    exp = comet_ml.start(\n",
    "        workspace=\"David-Eland\",\n",
    "        project_name=\"kp-lead-scoring-model\"\n",
    "    )\n",
    "    if exp is not None:\n",
    "        exp.set_name(\"250920-E1-regression-colab\")\n",
    "        exp.add_tags([\"colab\", \"lead-scoring\", \"baseline\"])\n",
    "except Exception as comet_exc:\n",
    "    print(f\"Comet ML logging disabled: {comet_exc}\")\n",
    "# --- END Comet setup ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Deland78/KP_Lead_Scoring_Colab/blob/main/KP_Lead_Scoring_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7NFojzrJLis"
   },
   "source": [
    "# KP Lead Scoring Model\\n\n",
    "Custom lead scoring model built for education leads requiring sales follow-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iD2LVJ4lJLit",
    "outputId": "3b4f6ecb-0fc7-4977-8c8e-4dd3fad44272"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1934094127.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport pandas as pd\\n\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "DEFAULT_INTENT_SCORE = 2\n",
    "DEFAULT_TIMING_SCORE = 3\n",
    "DEFAULT_CHANNEL_SCORE = 3\n",
    "DEFAULT_EDUCATION_SCORE = 3\n",
    "\n",
    "INTENT_SCORES = {\n",
    "    'Ready to enrol': 10,\n",
    "    'Ready to enroll': 10,\n",
    "    'Readytoenrol': 10,\n",
    "    'Looking for more information': 6,\n",
    "    'Researching options': 3,\n",
    "    'Unknown': 2,\n",
    "    'unsure': 2,\n",
    "}\n",
    "\n",
    "TIMING_SCORES = {\n",
    "    'within 3 months': 8,\n",
    "    'within 6 months': 5,\n",
    "    'within 12 months': 2,\n",
    "    '12 months plus': 1,\n",
    "    'unsure': 3,\n",
    "}\n",
    "\n",
    "CHANNEL_SCORES = {\n",
    "    'Unknown': 8,\n",
    "    'Referral': 7,\n",
    "    'Traditional': 6,\n",
    "    'Corporate': 5,\n",
    "    'SEO': 3,\n",
    "    'Affinity': 2,\n",
    "    'Email List': 1,\n",
    "    'PPI': 1,\n",
    "    'PPC': 3,\n",
    "}\n",
    "\n",
    "EDUCATION_SCORES = {\n",
    "    'Graduate / Masters Degree': 6,\n",
    "    'Postgraduate Diploma': 5,\n",
    "    'Bachelors Degree': 4,\n",
    "    'Diploma': 3,\n",
    "    'Year 12': 2,\n",
    "    'Unknown': 3,\n",
    "}\n",
    "\n",
    "CONVERTED_VALUE_MAP = {\n",
    "    'yes': 1,\n",
    "    'y': 1,\n",
    "    'true': 1,\n",
    "    '1': 1,\n",
    "    'no': 0,\n",
    "    'n': 0,\n",
    "    'false': 0,\n",
    "    '0': 0,\n",
    "}\n",
    "\n",
    "def _build_lookup(mapping):\n",
    "    return {str(key).strip().casefold(): value for key, value in mapping.items()}\n",
    "\n",
    "INTENT_SCORE_LOOKUP = _build_lookup(INTENT_SCORES)\n",
    "TIMING_SCORE_LOOKUP = _build_lookup(TIMING_SCORES)\n",
    "CHANNEL_SCORE_LOOKUP = _build_lookup(CHANNEL_SCORES)\n",
    "EDUCATION_SCORE_LOOKUP = _build_lookup(EDUCATION_SCORES)\n",
    "\n",
    "COLUMN_ALIASES = {\n",
    "    'Intent To Enrol': 'Intent To Enroll',\n",
    "    'Intent to Enroll': 'Intent To Enroll',\n",
    "    'Intent to enrol': 'Intent To Enroll',\n",
    "    'Intent to Enrol': 'Intent To Enroll',\n",
    "    'IntentToEnrol': 'Intent To Enroll',\n",
    "    'IntentToEnroll': 'Intent To Enroll',\n",
    "    'When Would You Like To Begin Studying?': 'When Like To Begin Studying',\n",
    "    'When would you like to begin studying?': 'When Like To Begin Studying',\n",
    "    'When Like To Begin Studying?': 'When Like To Begin Studying',\n",
    "    'When would you like to begin studying': 'When Like To Begin Studying',\n",
    "    'Opportunity count': 'Opportunity Count',\n",
    "    'Opportunity_count': 'Opportunity Count',\n",
    "    'Opportunity Count ': 'Opportunity Count',\n",
    "    'OpportunityCount': 'Opportunity Count',\n",
    "    'Highest Level of Education': 'Highest Level Of Education',\n",
    "    'Highest level of education': 'Highest Level Of Education',\n",
    "    'Highest level Of Education': 'Highest Level Of Education',\n",
    "    'Converted?': 'Converted',\n",
    "    'converted': 'Converted',\n",
    "    'Converted ': 'Converted',\n",
    "    'Channel ': 'Channel',\n",
    "    'Channel Name': 'Channel',\n",
    "}\n",
    "\n",
    "REQUIRED_COLUMNS = [\n",
    "    'Intent To Enroll',\n",
    "    'When Like To Begin Studying',\n",
    "    'Channel',\n",
    "    'Opportunity Count',\n",
    "    'Highest Level Of Education',\n",
    "    'Converted',\n",
    "]\n",
    "\n",
    "def _map_value_to_score(value, lookup, default):\n",
    "    if pd.isna(value):\n",
    "        return default\n",
    "    key = str(value).strip().casefold()\n",
    "    return lookup.get(key, default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBivpb_nJLiu"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the cleaned data\n",
    "DATASET_PATH = 'KP_Lead_Scoring_Data_Cleaned.csv'\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.rename(columns={alias: canonical for alias, canonical in COLUMN_ALIASES.items() if alias in df.columns})\n",
    "\n",
    "if 'Converted' not in df.columns:\n",
    "    raise KeyError(\"The required 'Converted' column is missing from the dataset.\")\n",
    "\n",
    "converted_numeric = pd.to_numeric(df['Converted'], errors='coerce')\n",
    "if converted_numeric.isna().any():\n",
    "    normalized = df['Converted'].astype(str).str.strip().str.lower()\n",
    "    converted_numeric = normalized.map(CONVERTED_VALUE_MAP)\n",
    "if converted_numeric.isna().any():\n",
    "    raise ValueError(\"The 'Converted' column must contain numeric or binary yes/no values.\")\n",
    "df['Converted'] = converted_numeric.astype(int)\n",
    "\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "conversion_rate = (df['Converted'].mean() * 100)\n",
    "print(f\"Conversion rate: {conversion_rate:.2f}%\")\n",
    "print(f\"Total conversions: {df['Converted'].sum():,}\")\n",
    "\n",
    "if 'exp' in globals() and exp is not None:\n",
    "    class_counts = df['Converted'].value_counts().to_dict()\n",
    "    exp.log_other('dataset_path', DATASET_PATH)\n",
    "    exp.log_other('dataset_shape', f\"{df.shape[0]}x{df.shape[1]}\")\n",
    "    exp.log_metric('dataset_rows', int(df.shape[0]))\n",
    "    exp.log_metric('dataset_columns', int(df.shape[1]))\n",
    "    exp.log_metric('conversion_rate', float(df['Converted'].mean()))\n",
    "    for label, count in class_counts.items():\n",
    "        exp.log_metric(f'class_count_{label}', int(count))\n",
    "    exp.log_other('class_balance', json.dumps(class_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rv5-G-7uJLiv"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_lead_scoring_features(df):\n",
    "    'Create engineered features for lead scoring.'\n",
    "    df_features = df.copy()\n",
    "    df_features.columns = df_features.columns.str.strip()\n",
    "    rename_map = {alias: canonical for alias, canonical in COLUMN_ALIASES.items() if alias in df_features.columns}\n",
    "    df_features = df_features.rename(columns=rename_map)\n",
    "\n",
    "    missing_columns = [col for col in REQUIRED_COLUMNS if col not in df_features.columns]\n",
    "    if missing_columns:\n",
    "        raise KeyError(f\"Missing required columns for feature engineering: {missing_columns}\")\n",
    "\n",
    "    df_features['Intent_Score'] = df_features['Intent To Enroll'].apply(\n",
    "        lambda value: _map_value_to_score(value, INTENT_SCORE_LOOKUP, DEFAULT_INTENT_SCORE)\n",
    "    )\n",
    "    df_features['Timing_Score'] = df_features['When Like To Begin Studying'].apply(\n",
    "        lambda value: _map_value_to_score(value, TIMING_SCORE_LOOKUP, DEFAULT_TIMING_SCORE)\n",
    "    )\n",
    "    df_features['Channel_Score'] = df_features['Channel'].apply(\n",
    "        lambda value: _map_value_to_score(value, CHANNEL_SCORE_LOOKUP, DEFAULT_CHANNEL_SCORE)\n",
    "    )\n",
    "    opportunity_counts = pd.to_numeric(df_features['Opportunity Count'], errors='coerce').fillna(0)\n",
    "    df_features['Is_Returning_Contact'] = (opportunity_counts > 1).astype(int)\n",
    "    df_features['Education_Score'] = df_features['Highest Level Of Education'].apply(\n",
    "        lambda value: _map_value_to_score(value, EDUCATION_SCORE_LOOKUP, DEFAULT_EDUCATION_SCORE)\n",
    "    )\n",
    "\n",
    "    return df_features\n",
    "\n",
    "# Apply feature engineering\n",
    "df_features = create_lead_scoring_features(df)\n",
    "print('Feature engineering complete!')\n",
    "\n",
    "if 'exp' in globals() and exp is not None:\n",
    "    exp.log_other('feature_engineering_function', 'create_lead_scoring_features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcHF8WdGJLiv"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Select features and train model\n",
    "model_features = ['Intent_Score', 'Timing_Score', 'Channel_Score', 'Is_Returning_Contact', 'Education_Score']\n",
    "\n",
    "if 'exp' in globals() and exp is not None:\n",
    "    exp.log_other('model_feature_order', json.dumps(model_features))\n",
    "    exp.log_metric('feature_count', len(model_features))\n",
    "\n",
    "X = df_features[model_features]\n",
    "y = df_features['Converted']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "if 'exp' in globals() and exp is not None:\n",
    "    split_recipe = {\n",
    "        'test_size': 0.2,\n",
    "        'random_state': 42,\n",
    "        'stratify': 'Converted',\n",
    "    }\n",
    "    exp.log_other('train_test_split', json.dumps(split_recipe))\n",
    "    exp.log_metric('train_samples', int(len(X_train)))\n",
    "    exp.log_metric('test_samples', int(len(X_test)))\n",
    "    exp.log_metric('train_positive', int(y_train.sum()))\n",
    "    exp.log_metric('test_positive', int(y_test.sum()))\n",
    "    exp.log_metric('train_negative', int((y_train == 0).sum()))\n",
    "    exp.log_metric('test_negative', int((y_test == 0).sum()))\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "if 'exp' in globals() and exp is not None:\n",
    "    exp.log_other('scaler', 'StandardScaler')\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "\n",
    "if 'exp' in globals() and exp is not None:\n",
    "    exp.log_parameters({f'log_reg__{key}': value for key, value in model.get_params().items()})\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Model training complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68crRoJlJLiv"
   },
   "outputs": [],
   "source": [
    "\n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print('=== MODEL PERFORMANCE ===')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    print('\n",
    "Classification Report:')\n",
    "    print(report)\n",
    "\n",
    "    class_labels = [str(label) for label in model.classes_]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    disp.plot(ax=ax, colorbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    if 'exp' in globals() and exp is not None:\n",
    "        exp.log_figure(figure_name='confusion_matrix', figure=fig)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': model_features,\n",
    "        'Coefficient': model.coef_[0],\n",
    "        'Abs_Importance': np.abs(model.coef_[0]),\n",
    "    }).sort_values('Abs_Importance', ascending=False)\n",
    "\n",
    "    print('\n",
    "=== FEATURE IMPORTANCE ===')\n",
    "    print(importance_df)\n",
    "\n",
    "    joblib.dump(model, 'model.pkl')\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    print('Model and scaler saved to disk.')\n",
    "\n",
    "    if 'exp' in globals() and exp is not None:\n",
    "        exp.log_metric('accuracy', float(accuracy))\n",
    "        exp.log_metric('roc_auc', float(roc_auc))\n",
    "        exp.log_metric('precision', float(precision))\n",
    "        exp.log_metric('recall', float(recall))\n",
    "        exp.log_metric('f1_score', float(f1))\n",
    "        exp.log_confusion_matrix(matrix=cm.tolist(), labels=class_labels)\n",
    "        exp.log_other('classification_report', report)\n",
    "        exp.log_table('feature_coefficients.csv', importance_df)\n",
    "        exp.log_other('model_coefficients', importance_df.to_json(orient='records'))\n",
    "        exp.log_asset('model.pkl', logical_path='artifacts/model.pkl')\n",
    "        exp.log_asset('scaler.pkl', logical_path='artifacts/scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lyq2DSkrJLiv"
   },
   "outputs": [],
   "source": [
    "\n",
    "    def score_lead(intent_to_enroll, when_like_to_begin, channel, highest_education, opportunity_count):\n",
    "        'Score a new lead (0-100 scale).'\n",
    "\n",
    "        intent_score = _map_value_to_score(intent_to_enroll, INTENT_SCORE_LOOKUP, DEFAULT_INTENT_SCORE)\n",
    "        timing_score = _map_value_to_score(when_like_to_begin, TIMING_SCORE_LOOKUP, DEFAULT_TIMING_SCORE)\n",
    "        channel_score = _map_value_to_score(channel, CHANNEL_SCORE_LOOKUP, DEFAULT_CHANNEL_SCORE)\n",
    "        education_score = _map_value_to_score(highest_education, EDUCATION_SCORE_LOOKUP, DEFAULT_EDUCATION_SCORE)\n",
    "\n",
    "        if pd.isna(opportunity_count):\n",
    "            opportunity_count_value = 0\n",
    "        else:\n",
    "            try:\n",
    "                opportunity_count_value = int(float(opportunity_count))\n",
    "            except (TypeError, ValueError):\n",
    "                opportunity_count_value = 0\n",
    "        is_returning = 1 if opportunity_count_value > 1 else 0\n",
    "\n",
    "        features = np.array([[intent_score, timing_score, channel_score, is_returning, education_score]], dtype=float)\n",
    "\n",
    "        features_scaled = scaler.transform(features)\n",
    "        probability = model.predict_proba(features_scaled)[0, 1]\n",
    "\n",
    "        return float((probability * 100).round(2))\n",
    "\n",
    "    print('Lead scoring function ready!')\n",
    "\n",
    "    # Test examples\n",
    "    print('\n",
    "=== SCORING EXAMPLES ===')\n",
    "    print(f\"High priority: {score_lead('Ready to enrol', 'within 3 months', 'Referral', 'Bachelors Degree', 1)}\")\n",
    "    print(f\"Medium priority: {score_lead('Researching options', 'within 6 months', 'SEO', 'Diploma', 1)}\")\n",
    "    print(f\"Low priority: {score_lead('Researching options', 'within 12 months', 'Email List', 'Year 12', 1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a6myn9d7dl"
   },
   "outputs": [],
   "source": [
    "\n",
    "    # Dataset overview\n",
    "    print('=== DATASET OVERVIEW ===')\n",
    "    print(f'Shape: {df.shape}')\n",
    "    print(f\"Conversion rate: {df['Converted'].mean():.4f}\")\n",
    "\n",
    "    print('\n",
    "=== COLUMN SUMMARY ===')\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        print(f\"\n",
    "--- {col} ---\")\n",
    "        print(f'Data type: {df[col].dtype}')\n",
    "        print(f\"Missing values: {missing_count} ({missing_count / len(df) * 100:.1f}%)\")\n",
    "        print(f'Unique values: {df[col].nunique()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
