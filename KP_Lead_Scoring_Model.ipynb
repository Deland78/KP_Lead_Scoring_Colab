{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deland78/KP_Lead_Scoring_Colab/blob/main/KP_Lead_Scoring_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFrDDIAZhSl_"
      },
      "source": [
        "# KP Lead Scoring Model\\nCustom lead scoring model built for education leads requiring sales follow-up."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "import joblib\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Install & import\n",
        "%pip install -q comet_ml\n",
        "\n",
        "import comet_ml\n",
        "\n",
        "# 1) Log in once to store your API key securely in the Colab VM\n",
        "#    You'll be prompted for the key (you can find it in Comet -> top-right avatar -> Settings -> API key).\n",
        "comet_ml.login()\n",
        "\n",
        "# 2) Start an experiment and point it at your new project\n",
        "#    Replace with your Comet workspace and desired project name (the project will be auto-created if it doesn't exist).\n",
        "exp = comet_ml.start(\n",
        "    workspace=\"david-eland\",      # e.g., \"david-eland\"\n",
        "    project_name=\"kp-lead-scoring-model\" # any new or existing Comet project name\n",
        ")\n",
        "\n",
        "# (optional but nice) give the run a human-friendly name and tags\n",
        "exp.set_name(\"baseline-regression-colab\")\n",
        "exp.add_tags([\"colab\", \"lead-scoring\", \"baseline\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEMb47jkhTHT",
        "outputId": "298774ee-539d-43a1-9aae-68607bf5ad09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0ZEzvrNwFBhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3fedbe4"
      },
      "source": [
        "\n",
        "# IMPORTANT: Replace file name below with the actual file in the Collab\n",
        "# content folder (see folder icon in to the left).\n",
        "selected_file = '/content/DE_Lead_Scoring_Cleaned (2).csv' # Replace with your filename\n",
        "\n",
        "\n",
        "# Load the cleaned data using the selected file path\n",
        "df = pd.read_csv(selected_file)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Conversion rate: {(df['Converted'].sum() / len(df) * 100):.2f}%\")\n",
        "print(f\"Total conversions: {df['Converted'].sum():,}\")\n",
        "\n",
        "# Apply feature engineering\n",
        "df_features = create_lead_scoring_features(df)\n",
        "print(\"Feature engineering complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGP8yg3LhSmI"
      },
      "outputs": [],
      "source": [
        "# Select features and train model\n",
        "model_features = [\n",
        "    'Intent_Score',\n",
        "    'Timing_Score',\n",
        "    'Channel_Score',\n",
        "    'Is_Returning_Contact',\n",
        "    'Education_Score']\n",
        "    X = df_features[model_features]\n",
        "    y = df_features['Converted']\n",
        "    # Split data\\n\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\n\\n\n",
        "    # Scale features\\nscaler = StandardScaler()\\\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n#\n",
        "Train model\\nmodel = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\\nmodel.fit(X_train_scaled, y_train)\\n\\nprint(\\\"Model training complete!\\\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvXszt6dhSmI"
      },
      "outputs": [],
      "source": [
        "#Select features and train model\\nmodel_features = ['Intent_Score', 'Timing_score']\n",
        "def create_lead_scoring_features(df):\n",
        "    \"\"\"Create engineered features for lead scoring\"\"\"\n",
        "    df_features = df.copy()\n",
        "\n",
        "    # 1. INTENT URGENCY SCORE\n",
        "    intent_scores = {\n",
        "        'Ready to enrol': 10,\n",
        "        'Ready to enroll': 10,\n",
        "        'Readytoenrol': 10,\n",
        "        'Looking for more information': 6,\n",
        "        'Researching options': 3,\n",
        "        'Unknown': 2,\n",
        "        'unsure': 2\n",
        "    }\n",
        "\n",
        "    df_features['Intent_Score'] = df_features['Intent To Enroll'].fillna('Unknown').map(\n",
        "        lambda x: intent_scores.get(x, 2)\n",
        "    )\n",
        "\n",
        "    # 2. TIMING URGENCY SCORE\n",
        "    timing_scores = {\n",
        "        'within 3 months': 8,\n",
        "        'within 6 months': 5,\n",
        "        'within 12 months': 2,\n",
        "        '12 months plus': 1,\n",
        "        'unsure': 3\n",
        "    }\n",
        "\n",
        "    df_features['Timing_Score'] = df_features['When Like To Begin Studying'].fillna('unsure').map(\n",
        "        lambda x: timing_scores.get(x, 3)\n",
        "    )\n",
        "\n",
        "    # 3. CHANNEL PERFORMANCE SCORE\n",
        "    channel_scores = {\n",
        "        'Unknown': 8,\n",
        "        'Referral': 7,\n",
        "        'Traditional': 6,\n",
        "        'Corporate': 5,\n",
        "        'SEO': 3,\n",
        "        'Affinity': 2,\n",
        "        'Email List': 1,\n",
        "        'PPI': 1,\n",
        "        'PPC': 3\n",
        "    }\n",
        "\n",
        "    df_features['Channel_Score'] = df_features['Channel'].map(\n",
        "        lambda x: channel_scores.get(x, 3)\n",
        "    )\n",
        "\n",
        "    # 4. RETURNING CONTACT FEATURES\n",
        "    df_features['Is_Returning_Contact'] = (df_features['Opportunity Count'] > 1).astype(int)\n",
        "\n",
        "    # 5. EDUCATION LEVEL SCORE\n",
        "    education_scores = {\n",
        "        'Graduate / Masters Degree': 6,\n",
        "        'Postgraduate Diploma': 5,\n",
        "        'Bachelors Degree': 4,\n",
        "        'Diploma': 3,\n",
        "        'Year 12': 2,\n",
        "        'Unknown': 3\n",
        "    }\n",
        "\n",
        "    df_features['Education_Score'] = df_features['Highest Level Of Education'].fillna('Unknown').map(\n",
        "        lambda x: education_scores.get(x, 3)\n",
        "    )\n",
        "\n",
        "    return df_features\n",
        "\n",
        "# Apply feature engineering\n",
        "df_features = create_lead_scoring_features(df)\n",
        "\n",
        "print(\"Feature engineering complete!\") # Uncomment after applying feature engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRBvsr9ahSmJ"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "print(\\\"=== MODEL PERFORMANCE ===\\\")\n",
        "print(f\\\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\\\")\n",
        "print(f\\\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\\\")\n",
        "print(\\\"\\\\nClassification Report:\\\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Feature importance\n",
        "print(\\\"\\\\n=== FEATURE IMPORTANCE ===\\\")\n",
        "importance_df = pd.DataFrame({\n",
        "        'Feature': model_features,\n",
        "        'Coefficient': model.coef_[0],\n",
        "        'Abs_Importance': np.abs(model.coef_[0])\n",
        "}).sort_values('Abs_Importance', ascending=False)\n",
        "\n",
        "print(importance_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1abyEJ5hSmJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "import joblib\n",
        "\n",
        "# Load the cleaned data\n",
        "df = pd.read_csv('KP_Lead_Scoring_Data_Cleaned.csv')\n",
        "\n",
        "# FOR COMET: Log hyperparameters\n",
        "\n",
        "exp.log_parameter(\"dataset_path\", \"KP_Lead_Scoring_Data_Cleaned.csv\")\n",
        "exp.log_parameter(\"raw_rows\", len(df))\n",
        "exp.log_parameter(\"raw_cols\", df.shape[1])\n",
        "\n",
        "# FOR COMET: If 'Converted' exists now, log basic class balance (helps spot drift)\n",
        "if \"Converted\" in df.columns:\n",
        "    class_counts = df[\"Converted\"].value_counts().to_dict()\n",
        "    exp.log_metrics({\n",
        "        \"class_0_count_raw\": class_counts.get(0, 0),\n",
        "        \"class_1_count_raw\": class_counts.get(1, 0),\n",
        "    })\n",
        "\n",
        "def create_lead_scoring_features(df):\n",
        "    \"\"\"Create engineered features for lead scoring\"\"\"\n",
        "    df_features = df.copy()\n",
        "\n",
        "    # 1. INTENT URGENCY SCORE\n",
        "    intent_scores = {\n",
        "        'Ready to enrol': 10,\n",
        "        'Ready to enroll': 10,\n",
        "        'Readytoenrol': 10,\n",
        "        'Looking for more information': 6,\n",
        "        'Researching options': 3,\n",
        "        'Unknown': 2,\n",
        "        'unsure': 2\n",
        "    }\n",
        "\n",
        "    df_features['Intent_Score'] = df_features['Intent To Enroll'].fillna('Unknown').map(\n",
        "        lambda x: intent_scores.get(x, 2)\n",
        "    )\n",
        "\n",
        "    # FOR COMET: Record the exact features being used, so results are reproducible/comparable.\n",
        "\n",
        "    exp.log_parameter(\"feature_engineering_fn\", \"create_lead_scoring_features\")\n",
        "\n",
        "\n",
        "    # 2. TIMING URGENCY SCORE\n",
        "    timing_scores = {\n",
        "        'within 3 months': 8,\n",
        "        'within 6 months': 5,\n",
        "        'within 12 months': 2,\n",
        "        '12 months plus': 1,\n",
        "        'unsure': 3\n",
        "    }\n",
        "\n",
        "    df_features['Timing_Score'] = df_features['When Like To Begin Studying'].fillna('unsure').map(\n",
        "        lambda x: timing_scores.get(x, 3)\n",
        "    )\n",
        "\n",
        "    # 3. CHANNEL PERFORMANCE SCORE\n",
        "    channel_scores = {\n",
        "        'Unknown': 8,\n",
        "        'Referral': 7,\n",
        "        'Traditional': 6,\n",
        "        'Corporate': 5,\n",
        "        'SEO': 3,\n",
        "        'Affinity': 2,\n",
        "        'Email List': 1,\n",
        "        'PPI': 1,\n",
        "        'PPC': 3\n",
        "    }\n",
        "\n",
        "    df_features['Channel_Score'] = df_features['Channel'].map(\n",
        "        lambda x: channel_scores.get(x, 3)\n",
        "    )\n",
        "\n",
        "    # 4. RETURNING CONTACT FEATURES\n",
        "    df_features['Is_Returning_Contact'] = (df_features['Opportunity Count'] > 1).astype(int)\n",
        "\n",
        "    # 5. EDUCATION LEVEL SCORE\n",
        "    education_scores = {\n",
        "        'Graduate / Masters Degree': 6,\n",
        "        'Postgraduate Diploma': 5,\n",
        "        'Bachelors Degree': 4,\n",
        "        'Diploma': 3,\n",
        "        'Year 12': 2,\n",
        "        'Unknown': 3\n",
        "    }\n",
        "\n",
        "    df_features['Education_Score'] = df_features['Highest Level Of Education'].fillna('Unknown').map(\n",
        "        lambda x: education_scores.get(x, 3)\n",
        "    )\n",
        "\n",
        "    return df_features\n",
        "\n",
        "# Apply feature engineering\n",
        "df_features = create_lead_scoring_features(df)\n",
        "\n",
        "# Select features and train model\n",
        "model_features = ['Intent_Score', 'Timing_Score', 'Channel_Score', 'Is_Returning_Contact', 'Education_Score']\n",
        "\n",
        "# FOR COMET: Pin the feature list and order (critical for consistent scaling & coefficients).\n",
        "\n",
        "exp.log_parameter(\"model_features\", \",\".join(model_features))\n",
        "\n",
        "\n",
        "X = df_features[model_features]\n",
        "y = df_features['Converted']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# FOR COMET logging\n",
        "exp.log_parameters({\n",
        "    \"test_size\": 0.2,\n",
        "    \"random_state\": 42,\n",
        "    \"stratify\": True\n",
        "})\n",
        "\n",
        "exp.log_metrics({\n",
        "    \"n_train\": len(X_train),\n",
        "    \"n_test\": len(X_test)\n",
        "})\n",
        "\n",
        "# FOR COMET Optional : confirm class balance in the split\n",
        "exp.log_metrics({\n",
        "    \"y_train_pos\": int(y_train.sum()),\n",
        "    \"y_train_neg\": int((y_train==0).sum()),\n",
        "    \"y_test_pos\": int(y_test.sum()),\n",
        "    \"y_test_neg\": int((y_test==0).sum()),\n",
        "})\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# FOR COMET logging: Not strictly required, but useful to know preprocessing happened\n",
        "exp.log_parameter(\"scaler\", \"StandardScaler\")\n",
        "\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
        "\n",
        "# FOR COMET Lock in model hyperparameters actually used in this run\n",
        "\n",
        "exp.log_parameters({\n",
        "    \"model_type\": \"LogisticRegression\",\n",
        "    \"class_weight\": \"balanced\",\n",
        "    \"max_iter\": 1000,\n",
        "    \"model_random_state\": 42\n",
        "})\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# FOR COMET EVALUATION & LOGGING (ADD AFTER model.fit)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predictions & probabilities for metrics\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Compute metrics you care about\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_proba)\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "\n",
        "# Log scalar metrics to Comet\n",
        "exp.log_metrics({\n",
        "    \"accuracy\": accuracy,\n",
        "    \"auc\": auc,\n",
        "    \"precision_neg\": report[\"0\"][\"precision\"],\n",
        "    \"recall_neg\": report[\"0\"][\"recall\"],\n",
        "    \"f1_neg\": report[\"0\"][\"f1-score\"],\n",
        "    \"precision_pos\": report[\"1\"][\"precision\"],\n",
        "    \"recall_pos\": report[\"1\"][\"recall\"],\n",
        "    \"f1_pos\": report[\"1\"][\"f1-score\"],\n",
        "})\n",
        "\n",
        "# Option A: log the confusion matrix as raw numbers (always safe)\n",
        "exp.log_metrics({\n",
        "    \"cm_00\": int(cm[0,0]),\n",
        "    \"cm_01\": int(cm[0,1]),\n",
        "    \"cm_10\": int(cm[1,0]),\n",
        "    \"cm_11\": int(cm[1,1]),\n",
        "})\n",
        "\n",
        "# Option B (nice to have): log a plot of the confusion matrix\n",
        "# (If you prefer a figure in the Comet UI)\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xticks([0,1], ['Neg (0)','Pos (1)'])\n",
        "plt.yticks([0,1], ['Neg (0)','Pos (1)'])\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, cm[i,j], ha='center', va='center')\n",
        "plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "exp.log_figure(figure_name=\"confusion_matrix\", figure=fig)\n",
        "plt.close(fig)\n",
        "\n",
        "# FOR COMET: Save and upload artifacts (handy for re-use)\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, \"lead_scoring_model.pkl\")\n",
        "joblib.dump(scaler, \"lead_scoring_scaler.pkl\")\n",
        "\n",
        "exp.log_asset(\"lead_scoring_model.pkl\")\n",
        "exp.log_asset(\"lead_scoring_scaler.pkl\")\n",
        "\n",
        "\n",
        "def score_lead(intent_to_enroll, when_like_to_begin, channel, highest_education, opportunity_count):\n",
        "    \"\"\"Score a new lead (0-100 scale)\"\"\"\n",
        "\n",
        "    intent_scores = {'Ready to enrol': 10, 'Ready to enroll': 10, 'Looking for more information': 6, 'Researching options': 3, 'Unknown': 2, 'unsure': 2}\n",
        "    timing_scores = {'within 3 months': 8, 'within 6 months': 5, 'within 12 months': 2, '12 months plus': 1, 'unsure': 3}\n",
        "    channel_scores = {'Unknown': 8, 'Referral': 7, 'Traditional': 6, 'Corporate': 5, 'SEO': 3, 'Affinity': 2, 'Email List': 1, 'PPI': 1, 'PPC': 3}\n",
        "    education_scores = {'Graduate / Masters Degree': 6, 'Postgraduate Diploma': 5, 'Bachelors Degree': 4, 'Diploma': 3, 'Year 12': 2, 'Unknown': 3}\n",
        "\n",
        "    # Calculate scores\n",
        "    intent_score = intent_scores.get(intent_to_enroll, 2)\n",
        "    timing_score = timing_scores.get(when_like_to_begin, 3)\n",
        "    channel_score = channel_scores.get(channel, 3)\n",
        "    education_score = education_scores.get(highest_education, 3)\n",
        "    is_returning = 1 if opportunity_count > 1 else 0\n",
        "\n",
        "    # Create feature array and convert to DataFrame with correct column names\n",
        "    features = np.array([[intent_score, timing_score, channel_score, is_returning, education_score]])\n",
        "    features_df = pd.DataFrame(features, columns=model_features)\n",
        "\n",
        "\n",
        "    # Scale and predict\n",
        "    features_scaled = scaler.transform(features_df)\n",
        "    probability = model.predict_proba(features_scaled)[:, 1][0]\n",
        "\n",
        "    return (probability * 100).round(2)\n",
        "\n",
        "print(\"Lead scoring function ready!\")\n",
        "\n",
        "# Test examples\n",
        "print(\"\\n=== SCORING EXAMPLES ===\")\n",
        "print(f\"High priority: {score_lead('Ready to enrol', 'within 3 months', 'Referral', 'Bachelors Degree', 1)}\")\n",
        "print(f\"Medium priority: {score_lead('Researching options', 'within 6 months', 'SEO', 'Diploma', 1)}\")\n",
        "print(f\"Low priority: {score_lead('Researching options', 'within 12 months', 'Email List', 'Year 12', 1)}\")\n",
        "\n",
        "# FOR COMET:End of Notebook\n",
        "exp.end()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}